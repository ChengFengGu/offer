# 熵

对于$P(X) = P(X=x) (x \in R)$，其熵为：

$$
H(X) = -\sum_{x\in R}P(x)log_{2}P(x)
$$

其实它就类似于一个期望的公式，不同的是 ，它衡量的是信息的无序程度。 观察其单调性可以看出来，当一个事件越确定（概率很大，或很小），那么，它的熵就越高。反之，则越低。


例如，一个二元的信息熵可以表示为：


$$
H(X)=-p(x) \log _{2} p(x)-(1-p(x)) \log _{2} p(x)
$$

它的变化